{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "from torch import nn, autograd\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment One\n",
    "$$x \\to Bernulli(0.5)$$ \n",
    "$$y|x = 0 \\to Bernulli(0.9)$$ \n",
    "$$y|x = 1 \\to Bernulli(0.3)$$\n",
    "\n",
    "we use a linear-> sigmoid regression to learn the conditional probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters and model\n",
    "sig = nn.Sigmoid()\n",
    "W = Variable(torch.rand(1), requires_grad=True)\n",
    "b = Variable(torch.rand(1), requires_grad=True)\n",
    "def net(x):\n",
    "    y_ = W*x + b\n",
    "    y_ = sig(y_)\n",
    "    loss = -(y*torch.log(y_) + (1-y)*torch.log(1-y_)) \n",
    "    return y_, loss\n",
    "\n",
    "def gen_data():\n",
    "    x = Variable(torch.bernoulli(torch.ones(1)*0.5))\n",
    "    if x.data.numpy() == 0:\n",
    "        y = Variable(torch.bernoulli(torch.ones(1)*0.9))\n",
    "    else:\n",
    "        y = Variable(torch.bernoulli(torch.ones(1)*0.3))\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.05\n",
    "for t in range(1,2000):\n",
    "    x,y = gen_data()\n",
    "    y_, loss = net(x)\n",
    "    loss.backward()\n",
    "    b.data -= learning_rate * b.grad.data\n",
    "    b.grad.data.zero_()\n",
    "    W.data -= learning_rate * W.grad.data\n",
    "    W.grad.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True para is 0.3, the perdiction is [ 0.29190451]\n",
      "True para is 0.9, the perdiction is [ 0.91689456]\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "x = Variable(torch.ones(1))\n",
    "y_,_ = net(x)\n",
    "print('True para is 0.3, the perdiction is {}'.format(y_.data.numpy()))\n",
    "\n",
    "x = Variable(torch.ones(1)*0)\n",
    "y_,_ = net(x)\n",
    "print('True para is 0.9, the perdiction is {}'.format(y_.data.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More compact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_in, D_out = 1, 1\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(D_in, D_out),\n",
    "    torch.nn.Sigmoid()\n",
    ")\n",
    "loss_fn = torch.nn.BCELoss()\n",
    "learning_rate = 0.02\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "for t in range(2000):\n",
    "    x,y = gen_data()\n",
    "    y_pred = model(x)\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True para is 0.3, the perdiction is [ 0.34832135]\n",
      "True para is 0.9, the perdiction is [ 0.90798932]\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "x = Variable(torch.ones(1))\n",
    "y_ = model(x)\n",
    "print('True para is 0.3, the perdiction is {}'.format(y_.data.numpy()))\n",
    "\n",
    "x = Variable(torch.ones(1)*0)\n",
    "y_ = model(x)\n",
    "print('True para is 0.9, the perdiction is {}'.format(y_.data.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "N, D_in, D_out =50, 1, 1\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(D_in, D_out),\n",
    "    torch.nn.Sigmoid()\n",
    ")\n",
    "loss_fn = torch.nn.BCELoss()\n",
    "learning_rate = 0.02\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "for t in range(2000):\n",
    "    data = [gen_data() for _ in range(N)]\n",
    "    x = torch.cat([i for i,_ in data]).view(N, D_in)\n",
    "    y = torch.cat([j for _,j in data]).view(N, D_out)\n",
    "    y_pred = model(x)\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    #if t%100 == 0:\n",
    "    #    print(t, loss.data[0])\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True para is 0.3, the perdiction is [ 0.2888166]\n",
      "True para is 0.9, the perdiction is [ 0.90217209]\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "x = Variable(torch.ones(1))\n",
    "y_ = model(x)\n",
    "print('True para is 0.3, the perdiction is {}'.format(y_.data.numpy()))\n",
    "\n",
    "x = Variable(torch.ones(1)*0)\n",
    "y_ = model(x)\n",
    "print('True para is 0.9, the perdiction is {}'.format(y_.data.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeding learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0_imbd is \n",
      " [ 0.944502   -0.3706497  -1.83810687  0.23389538  1.62372994  0.39470863\n",
      " -2.22684503  1.26098907  2.35926294 -0.31866524] \n",
      "1_imbd is \n",
      " [ 0.27534598  0.17846633  0.22618195 -0.24257904 -0.77979839  0.3432427\n",
      "  0.41293901  1.77549076  0.92081589  0.19707948]\n"
     ]
    }
   ],
   "source": [
    "# embed 0,1 into vectors V[0],V[1]\n",
    "im_D = 10\n",
    "h_D = 50\n",
    "V = torch.randn(2,10)\n",
    "print('0_imbd is \\n {} \\n1_imbd is \\n {}'.format(V[0].numpy(), V[1].numpy()))\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(im_D, h_D),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(h_D, im_D))\n",
    "\n",
    "def tran():\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
