{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import torch\n",
    "import time\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from torch.autograd import Variable\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, we focus on a simple road map (rep as a graph below), and generate random path on it.\n",
    "<img src=\"img/naive_road.png\" alt=\"Drawing\" style=\"width: 400px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(x, N = 24):\n",
    "    l = np.zeros(24)\n",
    "    l[x] = 1\n",
    "    return l\n",
    "def inv_one_hot(l, N = 24):\n",
    "    return np.argmax(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_graph():\n",
    "    G=nx.Graph()\n",
    "    G.add_nodes_from(range(24))\n",
    "    G.add_edges_from([(i, i+1) for i in range(5)] \n",
    "                     + [(i+6, i+7) for i in range(5)] \n",
    "                     +[(i+12, i+13) for i in range(5)]\n",
    "                     + [(i+18, i+19) for i in range(5)]\n",
    "                     + [(0,6),(6,12), (12,18)]\n",
    "                     + [(pair[0]+1, pair[1]+1) for pair in [(0,6),(6,12), (12,18)]]\n",
    "                     + [(pair[0]+2, pair[1]+2) for pair in [(0,6),(6,12), (12,18)]]\n",
    "                     + [(pair[0]+3, pair[1]+3) for pair in [(0,6),(6,12), (12,18)]]\n",
    "                     + [(pair[0]+4, pair[1]+4) for pair in [(0,6),(6,12), (12,18)]]\n",
    "                     + [(pair[0]+5, pair[1]+5) for pair in [(0,6),(6,12), (12,18)]]\n",
    "                     )\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gloable env\n",
    "G = build_graph() \n",
    "N = len(G.node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_path(start = None, stop_prob = 0.1):\n",
    "    \"\"\"\n",
    "    Generate (hist dependent) random path on graph G with lenght at least 2, encode each road in one-hot fashion\n",
    "    \"\"\"\n",
    "    if not start:\n",
    "        start = np.random.choice(24)\n",
    "    path = [start]\n",
    "    prev = None\n",
    "    while True:\n",
    "        neighbors = list(G.neighbors(start))\n",
    "        if prev:\n",
    "            neighbors.remove(prev)\n",
    "        nxt = np.random.choice(neighbors)\n",
    "        path.append(nxt)\n",
    "        prev = start\n",
    "        start = nxt\n",
    "        if np.random.rand() < stop_prob:\n",
    "            break\n",
    "    return np.array(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11 10  9 15 16 22 21 15 14  8  2  1  7  6 12 18]\n"
     ]
    }
   ],
   "source": [
    "p = random_path()\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_training_set():\n",
    "    def f(x):\n",
    "        if x == -1:\n",
    "            return 0\n",
    "        if x == -6:\n",
    "            return 1\n",
    "        if x == 1:\n",
    "            return 2\n",
    "        if x == 6:\n",
    "            return 3\n",
    "    path = random_path()\n",
    "    inp = torch.from_numpy(np.float32(np.array([one_hot(p) for p in path[:-1]])))\n",
    "    #import pdb; pdb.set_trace()\n",
    "    tar = [f(x) for x in path[1:] - path[:-1]]\n",
    "    tar = torch.from_numpy(np.array(tar))\n",
    "    return Variable(inp).contiguous(), Variable(tar).contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [15, 9, 10, 11] is the sequence of road\n",
      "y: [1 2 2 3] denotes the turning decistion at each road\n"
     ]
    }
   ],
   "source": [
    "x,y = random_training_set()\n",
    "print('x: {} is the sequence of road'.format([inv_one_hot(r) for r in x.data.numpy()]))\n",
    "print('y: {} denotes the turning decistion at each road'.format(y.data.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 24])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we know the road transition are markov (turing decision only depends on current road), let start with *none-recurrent nn* to fit our transition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.38114690781\n",
      "1000 1.35140927243\n",
      "2000 1.33301620263\n",
      "3000 1.33315615296\n",
      "4000 1.33078861767\n",
      "5000 1.32967023289\n",
      "6000 1.33005973268\n",
      "7000 1.32692051202\n",
      "8000 1.32590233856\n",
      "9000 1.32463343316\n",
      "10000 1.32579139608\n",
      "11000 1.32360570788\n",
      "12000 1.32427185416\n",
      "13000 1.32487459326\n",
      "14000 1.322965734\n",
      "15000 1.32493304294\n",
      "16000 1.32282043344\n",
      "17000 1.32387889814\n",
      "18000 1.3248312844\n",
      "19000 1.32466875798\n",
      "20000 1.3243188622\n",
      "21000 1.32348152477\n",
      "22000 1.32424427032\n",
      "23000 1.32434571075\n",
      "24000 1.31884635252\n",
      "25000 1.32293784672\n",
      "26000 1.32197898549\n",
      "27000 1.32298615849\n",
      "28000 1.32584601378\n",
      "29000 1.32265436441\n",
      "30000 1.32368558639\n",
      "31000 1.32451673508\n",
      "32000 1.32343172765\n",
      "33000 1.32197354162\n",
      "34000 1.3234498297\n",
      "35000 1.32258604032\n",
      "36000 1.3231948024\n",
      "37000 1.32299002028\n",
      "38000 1.32473841596\n",
      "39000 1.32514066863\n"
     ]
    }
   ],
   "source": [
    "N_batch, D_in, D_hidden, D_out = 50, 24, 100, 4\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(D_in, D_hidden),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(D_hidden, D_out),\n",
    "    torch.nn.Softmax(dim = 1),\n",
    ")\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "learning_rate = 0.002\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "L = 0\n",
    "n = 0\n",
    "pts = {'x':[], 'y':[]}\n",
    "for t in range(40000):\n",
    "    x,y = random_training_set()\n",
    "    y_pred = model(x)\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    L += sum(loss.data.numpy())\n",
    "    n += len(loss.data.numpy())\n",
    "    if t%1000 == 0:\n",
    "        pts['x'].append(t)\n",
    "        pts['y'].append(L/n)\n",
    "        print(t, L/n)\n",
    "        L = 0\n",
    "        n = 0\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x11209dcc0>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x112031588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(pts['x'],pts['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 4, 5, 11, 10, 16]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0.2651  0.2600  0.2330  0.2419\n",
       " 0.4092  0.0000  0.3269  0.2639\n",
       " 0.5015  0.0003  0.0000  0.4982\n",
       " 0.3330  0.3372  0.0000  0.3297\n",
       " 0.2651  0.2600  0.2330  0.2419\n",
       " 0.2576  0.2648  0.2443  0.2334\n",
       "[torch.FloatTensor of size 6x4]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y = random_training_set()\n",
    "print([inv_one_hot(r) for r in x.data.numpy()])\n",
    "model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, the naive nn is not enough.\n",
    "# RNN for Tracking the History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, n_layers=1):\n",
    "        super(RNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.gru = nn.GRU(input_size, hidden_size, n_layers)\n",
    "        self.lin = nn.Linear(hidden_size, output_size)\n",
    "        self.sm = nn.Softmax(dim = 2)\n",
    "        \n",
    "        hidden0 = torch.zeros(n_layers, 1, hidden_size)\n",
    "        self.hidden0 = nn.Parameter(hidden0, requires_grad=True)\n",
    "    \n",
    "    def forward(self, inp, hidden):\n",
    "        output, hidden = self.gru(inp.view(1, 1, self.input_size), hidden)\n",
    "        output = self.lin(output) \n",
    "        output = self.sm(output)\n",
    "        return output, hidden\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        return self.hidden0\n",
    "    #def init_hidden(self):\n",
    "    #    return Variable(torch.zeros(self.n_layers, 1, self.hidden_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(inp, target):\n",
    "    hidden = rnn.init_hidden() \n",
    "    rnn.zero_grad()\n",
    "    hat = []\n",
    "    for i in range(len(inp)):\n",
    "        output, hidden = rnn(inp[i,:], hidden)\n",
    "        hat.append(output.view(-1,4))\n",
    "    pred = torch.cat(hat)\n",
    "    loss = loss_fn(pred, target)\n",
    "    rnn_optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    rnn_optimizer.step()\n",
    "    return pred, loss.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_batch, D_in, D_hidden, D_out = 50, 24, 200, 4\n",
    "rnn = RNN(D_in, D_hidden, D_out, n_layers = 1)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "learning_rate = 0.0002\n",
    "rnn_optimizer = torch.optim.Adam(rnn.parameters(), lr=learning_rate)\n",
    "L = 0\n",
    "pts = {'x':[], 'y':[]}\n",
    "for t in range(1,400001):\n",
    "    x,y = random_training_set()\n",
    "    _, loss = train(x,y)\n",
    "    \n",
    "    L += loss\n",
    "    if t%10000 == 0:\n",
    "        pts['x'].append(t)\n",
    "        pts['y'].append(L/10000)\n",
    "        print(t, L/10000)\n",
    "        L = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(pts['x'],pts['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = random_training_set()\n",
    "pred,_ = train(x,y)\n",
    "print([inv_one_hot(r) for r in x.data.numpy()])\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 1000\n",
    "print_every = 100\n",
    "#plot_every = 10\n",
    "input_size = 24 # one hot encoding for 24 node in the graph\n",
    "hidden_size = 200\n",
    "output_size = 4 #?? distriubtuion for 4 exits??\n",
    "n_layers = 2\n",
    "lr = 0.005\n",
    "\n",
    "rnn = RNN(input_size, hidden_size, output_size, n_layers)\n",
    "rnn_optimizer = torch.optim.Adam(rnn.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "start = time.time()\n",
    "all_losses = []\n",
    "loss_avg = 0\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    loss = train(*random_training_set())       \n",
    "    loss_avg += loss\n",
    "\n",
    "    if epoch % print_every == 0:\n",
    "        print('[(%d %d%%) %.4f]' % (epoch, epoch / n_epochs * 100, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(start):\n",
    "    hidden = rnn.init_hidden()\n",
    "    inp = start\n",
    "    predicted = inp.data.view(1,2)\n",
    "    \n",
    "    for i in range(1, 1000):\n",
    "        output, hidden = rnn(inp, hidden)\n",
    "        predicted = torch.cat([predicted, output.data.view(1,2)])\n",
    "        inp = output\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = random_training_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden = rnn.init_hidden()\n",
    "o,h = rnn(x[0], hidden)\n",
    "print(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
