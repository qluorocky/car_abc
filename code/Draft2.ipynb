{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imp\n",
    "import Data\n",
    "import utils\n",
    "import Predictors, Road_Graph, Neural_Network\n",
    "imp.reload(Data)\n",
    "imp.reload(Neural_Network)\n",
    "imp.reload(utils)\n",
    "imp.reload(Predictors)\n",
    "imp.reload(Road_Graph)\n",
    "\n",
    "from Road_Graph import *\n",
    "from Predictors import *\n",
    "from Data import *\n",
    "from utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "from torch import nn, autograd\n",
    "import torch.nn.functional as F\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, we focus on a simple road map (rep as a graph below), and generate random path on it.\n",
    "<img src=\"../img/naive_road.png\" alt=\"Drawing\" style=\"width: 400px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_dict = {}\n",
    "graph_dict = graph_dict.fromkeys(range(24))\n",
    "edges = [(i, i+1) for i in range(5)] \\\n",
    "        + [(i+6, i+7) for i in range(5)]\\\n",
    "                        +[(i+12, i+13) for i in range(5)]\\\n",
    "                     + [(i+18, i+19) for i in range(5)]\\\n",
    "                     + [(0,6),(6,12), (12,18)]\\\n",
    "                     + [(pair[0]+1, pair[1]+1) for pair in [(0,6),(6,12), (12,18)]]\\\n",
    "                     + [(pair[0]+2, pair[1]+2) for pair in [(0,6),(6,12), (12,18)]]\\\n",
    "                     + [(pair[0]+3, pair[1]+3) for pair in [(0,6),(6,12), (12,18)]]\\\n",
    "                     + [(pair[0]+4, pair[1]+4) for pair in [(0,6),(6,12), (12,18)]]\\\n",
    "                     + [(pair[0]+5, pair[1]+5) for pair in [(0,6),(6,12), (12,18)]]\n",
    "for i,j in edges:\n",
    "    if not graph_dict[i]:\n",
    "        graph_dict[i] = [j]\n",
    "    else:\n",
    "        graph_dict[i].append(j)\n",
    "    if not graph_dict[j]:\n",
    "        graph_dict[j] = [i]\n",
    "    else:\n",
    "        graph_dict[j].append(i)\n",
    "\n",
    "graph = Road_Graph(graph_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markov Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_to_training_pair2(path):\n",
    "    return path[1:], path[:-1]\n",
    "\n",
    "def get_prob(x):\n",
    "    nb = graph.neighbors(x)\n",
    "    W_list = [W[j].view(-1,1) for j in nb]\n",
    "    Ws = torch.cat(W_list, dim = 1)\n",
    "    W_next = model(W[x])\n",
    "    #print('W_next:', W_next)\n",
    "    #print(W_next.size(), Ws.size())\n",
    "    W_next_rep = W_next.view(-1,1).repeat(1,Ws.size()[1])\n",
    "    #print(W_next_rep.size(), Ws.size())\n",
    "    logit = torch.sum(W_next_rep*Ws, 0)\n",
    "    prob = F.softmax(logit, dim = 0)\n",
    "    return prob\n",
    "\n",
    "def get_loss(x, y):\n",
    "    nb = graph.neighbors(x)\n",
    "    #import pdb; pdb.set_trace()\n",
    "    W_list = [W[j].view(-1,1) for j in nb]\n",
    "    Ws = torch.cat(W_list, dim = 1)\n",
    "    W_next = model(W[x])\n",
    "    #print('W_next:', W_next)\n",
    "    #print(W_next.size(), Ws.size())\n",
    "    W_next_rep = W_next.view(-1,1).repeat(1,Ws.size()[1])\n",
    "    #print(W_next_rep.size(), Ws.size())\n",
    "    logit = torch.sum(W_next_rep*Ws, 0)\n",
    "    prob = F.softmax(logit, dim = 0)\n",
    "    loss = -torch.log(prob[np.where(nb == y)])\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.FloatTensor\n",
    "\n",
    "data = random_walk_data(graph,10000)\n",
    "\n",
    "im_D = 5\n",
    "N = 24\n",
    "h_D = 100\n",
    "\n",
    "\n",
    "loss_list = []\n",
    "W = Variable(torch.randn(N,im_D).type(dtype), requires_grad=True)\n",
    "model = torch.nn.Sequential(\n",
    "        torch.nn.Linear(im_D, h_D),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(h_D, im_D),\n",
    "    )\n",
    "for k in range(len(data)):\n",
    "    path = data[k]\n",
    "    x,y = path_to_training_pair2(path)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(list(model.parameters()) + [W], lr=0.001) # remove [W] for a fixed random embeding\n",
    "    for i in range(len(x)):\n",
    "        loss = get_loss(x[i], y[i])\n",
    "        loss_list.append(loss)\n",
    "        \n",
    "    if k%50 == 0:\n",
    "        batch_loss = torch.sum(torch.cat(loss_list)) / len(loss_list)\n",
    "        optimizer.zero_grad()\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_list = []\n",
    "        print(batch_loss.data.numpy())\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'W' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-5c4d08b2384d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m24\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mopt_log_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-16-5c4d08b2384d>\u001b[0m in \u001b[0;36mopt_log_loss\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m24\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m24\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-15aa11930873>\u001b[0m in \u001b[0;36mget_prob\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mnb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mW_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mWs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mW_next\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-15aa11930873>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mnb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mW_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mWs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mW_next\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'W' is not defined"
     ]
    }
   ],
   "source": [
    "def opt_log_loss():\n",
    "    s = 0\n",
    "    for i in range(24):\n",
    "        n = len(get_prob(i)) - 1\n",
    "        s += -np.sum(np.ones(n) /n * np.log(np.ones(n)/n))\n",
    "    return s/24\n",
    "opt_log_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opt_log_loss():\n",
    "    s = 0\n",
    "    for i in range(24):\n",
    "        p_ = get_prob(i).data.numpy()\n",
    "        n = len(get_prob(i))\n",
    "        s += -np.sum(np.ones(n) /n * np.log(np.ones(n)/n))\n",
    "    return s/24\n",
    "opt_log_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_loss():\n",
    "    s = 0\n",
    "    for i in range(24):\n",
    "        p_ = get_prob(i).data.numpy()\n",
    "        n = len(get_prob(i))\n",
    "        s += -np.sum(np.ones(n) /n * np.log(p_))\n",
    "    return s/24\n",
    "log_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_loss():\n",
    "    s = 0\n",
    "    for i in range(24):\n",
    "        p_ = get_prob(i).data.numpy()\n",
    "        n = len(get_prob(i))\n",
    "        s += -np.sum(np.ones(n) /n * np.log(p_))\n",
    "    return s/24\n",
    "log_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_prob(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hist Dependent Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, n_layers=1):\n",
    "        super(RNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.gru = nn.GRU(input_size, hidden_size, n_layers)\n",
    "        self.lin = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, inp, hidden):\n",
    "        output, hidden = self.gru(inp.view(1, 1, self.input_size), hidden)\n",
    "        output = self.lin(output) \n",
    "        return output, hidden        \n",
    "\n",
    "    def init_hidden(self):\n",
    "        return Variable(torch.zeros(self.n_layers, 1, self.hidden_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_loss(path):\n",
    "    h = model.init_hidden()\n",
    "    output_list = []\n",
    "    for i in path:\n",
    "        o, h = model(W[i], h)\n",
    "        output_list.append(o)\n",
    "    loss_list = []\n",
    "    for i in range(len(path) - 1):\n",
    "        x = path[i]\n",
    "        y = path[i+1]\n",
    "        nb = graph.neighbors(x)\n",
    "        W_list = [W[j].view(-1,1) for j in nb]\n",
    "        Ws = torch.cat(W_list, dim = 1)\n",
    "        W_next = output_list[i]\n",
    "        W_next_rep = W_next.view(-1,1).repeat(1,Ws.size()[1])\n",
    "        logit = torch.sum(W_next_rep*Ws, 0)\n",
    "        prob = F.softmax(logit, dim = 0)\n",
    "        loss_list.append(-torch.log(prob[np.where(nb == y)]))\n",
    "    return torch.sum(torch.cat(loss_list))\n",
    "\n",
    "def get_prob(path):\n",
    "    h = model.init_hidden()\n",
    "    for i in path:\n",
    "        o, h = model(W[i], h)\n",
    "    x = path[-1]\n",
    "    nb = graph.neighbors(x)\n",
    "    W_list = [W[j].view(-1,1) for j in nb]\n",
    "    Ws = torch.cat(W_list, dim = 1)\n",
    "    W_next = o\n",
    "    W_next_rep = W_next.view(-1,1).repeat(1,Ws.size()[1])\n",
    "    logit = torch.sum(W_next_rep*Ws, 0)\n",
    "    prob = F.softmax(logit, dim = 0)\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = random_walk_data(graph, 10000, go_back=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_D = 50\n",
    "N = 24\n",
    "h_D = 100\n",
    "dtype = torch.FloatTensor\n",
    "\n",
    "\n",
    "W = Variable(torch.randn(N,im_D).type(dtype), requires_grad=True)\n",
    "model = RNN(im_D, h_D, im_D)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) # remove [W] for a fixed random embeding\n",
    "\n",
    "loss_list = []\n",
    "s = 0\n",
    "for k in range(len(data)):\n",
    "    path = data[k]\n",
    "    loss = path_loss(path)\n",
    "    loss_list.append(loss)    \n",
    "    s += len(path)\n",
    "    if k%50 == 0:\n",
    "        batch_loss = torch.sum(torch.cat(loss_list)) / s\n",
    "        s = 0\n",
    "        optimizer.zero_grad()\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_list = []\n",
    "        print(batch_loss.data.numpy())\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_prob([1,2,3,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modulized Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = random_walk_data(graph, 20000, go_back=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_pd = RNN_Predictor(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.49057841]\n",
      "[ 1.31368899]\n",
      "[ 1.21806753]\n",
      "[ 1.20786726]\n",
      "[ 1.16426241]\n",
      "[ 1.11113167]\n",
      "[ 1.08402061]\n",
      "[ 1.02662027]\n",
      "[ 1.08754182]\n",
      "[ 1.03246641]\n",
      "[ 1.02397311]\n",
      "[ 0.97215527]\n",
      "[ 0.9794023]\n",
      "[ 0.99841374]\n",
      "[ 0.95839667]\n",
      "[ 0.93975204]\n",
      "[ 0.93028617]\n",
      "[ 0.9550643]\n",
      "[ 0.93516916]\n",
      "[ 0.92080152]\n",
      "[ 0.91433632]\n",
      "[ 0.90261841]\n",
      "[ 0.8887884]\n",
      "[ 0.89584726]\n",
      "[ 0.88376725]\n",
      "[ 0.87292325]\n",
      "[ 0.90974182]\n",
      "[ 0.84714019]\n",
      "[ 0.86564213]\n",
      "[ 0.91250235]\n",
      "[ 0.8756271]\n",
      "[ 0.87300533]\n",
      "[ 0.83986932]\n",
      "[ 0.86106211]\n",
      "[ 0.85313326]\n",
      "[ 0.83331144]\n",
      "[ 0.84302658]\n",
      "[ 0.79348326]\n",
      "[ 0.84175235]\n",
      "[ 0.81325763]\n",
      "[ 0.82886684]\n",
      "[ 0.79469347]\n",
      "[ 0.82364309]\n",
      "[ 0.83853394]\n",
      "[ 0.80734676]\n",
      "[ 0.83412749]\n",
      "[ 0.8479777]\n",
      "[ 0.84218377]\n",
      "[ 0.83010334]\n",
      "[ 0.849352]\n",
      "[ 0.8261224]\n",
      "[ 0.8209154]\n",
      "[ 0.83725631]\n",
      "[ 0.84606367]\n",
      "[ 0.77279347]\n",
      "[ 0.81535184]\n",
      "[ 0.83273989]\n",
      "[ 0.82602894]\n",
      "[ 0.82573992]\n",
      "[ 0.8462832]\n",
      "[ 0.79583359]\n",
      "[ 0.81302643]\n",
      "[ 0.83354908]\n",
      "[ 0.80464822]\n",
      "[ 0.82740986]\n",
      "[ 0.79632878]\n",
      "[ 0.80040205]\n",
      "[ 0.81691951]\n",
      "[ 0.82699639]\n",
      "[ 0.81366253]\n",
      "[ 0.80883461]\n",
      "[ 0.81112063]\n",
      "[ 0.79650116]\n",
      "[ 0.79372472]\n",
      "[ 0.74549133]\n",
      "[ 0.81250364]\n",
      "[ 0.81599981]\n",
      "[ 0.83558041]\n",
      "[ 0.78479248]\n",
      "[ 0.84560317]\n",
      "[ 0.84833699]\n",
      "[ 0.78974187]\n",
      "[ 0.80225533]\n",
      "[ 0.81057578]\n",
      "[ 0.83604282]\n",
      "[ 0.78504962]\n",
      "[ 0.77883756]\n",
      "[ 0.80884713]\n",
      "[ 0.77032942]\n",
      "[ 0.78864348]\n",
      "[ 0.80803317]\n",
      "[ 0.80403405]\n",
      "[ 0.8188504]\n",
      "[ 0.7734248]\n",
      "[ 0.82203031]\n",
      "[ 0.79510754]\n",
      "[ 0.84094673]\n",
      "[ 0.80368358]\n",
      "[ 0.80685377]\n",
      "[ 0.80499989]\n",
      "[ 0.84668529]\n",
      "[ 0.80765355]\n",
      "[ 0.815328]\n",
      "[ 0.81620502]\n",
      "[ 0.78506756]\n",
      "[ 0.78969777]\n",
      "[ 0.78411299]\n",
      "[ 0.79200363]\n",
      "[ 0.83478177]\n",
      "[ 0.78059518]\n",
      "[ 0.83293331]\n",
      "[ 0.84851855]\n",
      "[ 0.79909408]\n",
      "[ 0.78358847]\n",
      "[ 0.81500238]\n",
      "[ 0.80187553]\n",
      "[ 0.78125364]\n",
      "[ 0.78683597]\n",
      "[ 0.78217614]\n",
      "[ 0.82153827]\n",
      "[ 0.77058834]\n",
      "[ 0.78942186]\n",
      "[ 0.78834653]\n",
      "[ 0.80270118]\n",
      "[ 0.79913062]\n",
      "[ 0.79137653]\n",
      "[ 0.80446732]\n",
      "[ 0.81522435]\n",
      "[ 0.80141181]\n",
      "[ 0.77687347]\n",
      "[ 0.8063364]\n",
      "[ 0.78021139]\n",
      "[ 0.8093729]\n",
      "[ 0.7757467]\n",
      "[ 0.80593818]\n",
      "[ 0.80388755]\n",
      "[ 0.8062135]\n",
      "[ 0.81953692]\n",
      "[ 0.82488924]\n",
      "[ 0.80188698]\n",
      "[ 0.78356618]\n",
      "[ 0.81010598]\n",
      "[ 0.82351226]\n",
      "[ 0.78766197]\n",
      "[ 0.79128402]\n",
      "[ 0.76234823]\n",
      "[ 0.79694551]\n",
      "[ 0.80746049]\n",
      "[ 0.76724112]\n",
      "[ 0.80499983]\n",
      "[ 0.80741715]\n",
      "[ 0.80408466]\n",
      "[ 0.78013057]\n",
      "[ 0.7956149]\n",
      "[ 0.80571759]\n",
      "[ 0.80513322]\n",
      "[ 0.81232345]\n",
      "[ 0.7838366]\n",
      "[ 0.82098192]\n",
      "[ 0.77819198]\n",
      "[ 0.79649556]\n",
      "[ 0.82318068]\n",
      "[ 0.78810769]\n",
      "[ 0.77592009]\n",
      "[ 0.81218964]\n",
      "[ 0.78479487]\n",
      "[ 0.76957041]\n",
      "[ 0.81047523]\n",
      "[ 0.81317282]\n",
      "[ 0.78642279]\n",
      "[ 0.81861955]\n",
      "[ 0.79206288]\n",
      "[ 0.79774153]\n",
      "[ 0.79147005]\n",
      "[ 0.82098526]\n",
      "[ 0.77534622]\n",
      "[ 0.78672963]\n",
      "[ 0.81349832]\n",
      "[ 0.78055584]\n",
      "[ 0.81857657]\n",
      "[ 0.81429428]\n",
      "[ 0.8180964]\n",
      "[ 0.81158477]\n",
      "[ 0.81570935]\n",
      "[ 0.82372117]\n",
      "[ 0.77538729]\n",
      "[ 0.78914815]\n",
      "[ 0.7909497]\n",
      "[ 0.79912901]\n",
      "[ 0.79640067]\n",
      "[ 0.79502708]\n",
      "[ 0.79281628]\n",
      "[ 0.80552292]\n",
      "[ 0.8082478]\n",
      "[ 0.78240883]\n",
      "[ 0.79455793]\n",
      "[ 0.76863974]\n",
      "[ 0.81078768]\n",
      "[ 0.76430851]\n",
      "[ 0.80993307]\n",
      "[ 0.79599088]\n",
      "[ 0.79061335]\n",
      "[ 0.82587582]\n",
      "[ 0.7970565]\n",
      "[ 0.80258733]\n",
      "[ 0.77407664]\n",
      "[ 0.77037823]\n",
      "[ 0.77815723]\n",
      "[ 0.79563546]\n",
      "[ 0.81275994]\n",
      "[ 0.77125025]\n",
      "[ 0.78356093]\n",
      "[ 0.7925511]\n",
      "[ 0.77714962]\n",
      "[ 0.80975801]\n",
      "[ 0.78391141]\n",
      "[ 0.79682308]\n",
      "[ 0.80135185]\n",
      "[ 0.7682457]\n",
      "[ 0.77425683]\n",
      "[ 0.79425371]\n",
      "[ 0.76660997]\n",
      "[ 0.81159234]\n",
      "[ 0.7980594]\n",
      "[ 0.78098065]\n",
      "[ 0.78347385]\n",
      "[ 0.78839189]\n",
      "[ 0.78530043]\n",
      "[ 0.80269378]\n",
      "[ 0.76166451]\n",
      "[ 0.77615899]\n",
      "[ 0.7775526]\n",
      "[ 0.80416769]\n",
      "[ 0.75777489]\n",
      "[ 0.78307295]\n",
      "[ 0.79973513]\n",
      "[ 0.81087101]\n",
      "[ 0.78924412]\n",
      "[ 0.80236036]\n",
      "[ 0.7978971]\n",
      "[ 0.78665543]\n",
      "[ 0.78604913]\n",
      "[ 0.78547883]\n",
      "[ 0.75777447]\n",
      "[ 0.75147313]\n",
      "[ 0.76405406]\n",
      "[ 0.82339609]\n",
      "[ 0.78472126]\n",
      "[ 0.79501802]\n",
      "[ 0.80033934]\n",
      "[ 0.76502424]\n",
      "[ 0.76612937]\n",
      "[ 0.78932899]\n",
      "[ 0.76626825]\n",
      "[ 0.78755862]\n",
      "[ 0.77027208]\n",
      "[ 0.77213353]\n",
      "[ 0.79782057]\n",
      "[ 0.7887761]\n",
      "[ 0.78448951]\n",
      "[ 0.80729616]\n",
      "[ 0.78523922]\n",
      "[ 0.76672417]\n",
      "[ 0.78065711]\n",
      "[ 0.765598]\n",
      "[ 0.79148537]\n",
      "[ 0.75837988]\n",
      "[ 0.80336225]\n",
      "[ 0.79897285]\n",
      "[ 0.74724334]\n",
      "[ 0.76702034]\n",
      "[ 0.7698127]\n",
      "[ 0.77213788]\n",
      "[ 0.79610234]\n",
      "[ 0.80007321]\n",
      "[ 0.80323774]\n",
      "[ 0.80710959]\n",
      "[ 0.79490662]\n",
      "[ 0.75639009]\n",
      "[ 0.7591607]\n",
      "[ 0.79120249]\n",
      "[ 0.76681781]\n",
      "[ 0.80290014]\n",
      "[ 0.777551]\n",
      "[ 0.78946745]\n",
      "[ 0.76969647]\n",
      "[ 0.78919512]\n",
      "[ 0.79457366]\n",
      "[ 0.80720574]\n",
      "[ 0.83036292]\n",
      "[ 0.75865102]\n",
      "[ 0.79099673]\n",
      "[ 0.80902678]\n",
      "[ 0.7757535]\n",
      "[ 0.81447238]\n",
      "[ 0.80384773]\n",
      "[ 0.77771121]\n",
      "[ 0.7770167]\n",
      "[ 0.8076669]\n",
      "[ 0.7768324]\n",
      "[ 0.81857896]\n",
      "[ 0.75305194]\n",
      "[ 0.76461655]\n",
      "[ 0.81212747]\n",
      "[ 0.76326811]\n",
      "[ 0.78491455]\n",
      "[ 0.78752822]\n",
      "[ 0.74606049]\n",
      "[ 0.8122853]\n",
      "[ 0.7826817]\n",
      "[ 0.79990679]\n",
      "[ 0.79555655]\n",
      "[ 0.78904194]\n",
      "[ 0.79354262]\n",
      "[ 0.79538393]\n",
      "[ 0.78684336]\n",
      "[ 0.7620489]\n",
      "[ 0.81296515]\n",
      "[ 0.77341104]\n",
      "[ 0.8061685]\n",
      "[ 0.79763001]\n",
      "[ 0.77304149]\n",
      "[ 0.77364773]\n",
      "[ 0.79542315]\n",
      "[ 0.76606721]\n",
      "[ 0.79482365]\n",
      "[ 0.7623319]\n",
      "[ 0.78552634]\n",
      "[ 0.77787632]\n",
      "[ 0.80548835]\n",
      "[ 0.77148694]\n",
      "[ 0.77344668]\n",
      "[ 0.77215701]\n",
      "[ 0.79319108]\n",
      "[ 0.78262657]\n",
      "[ 0.79740429]\n",
      "[ 0.75565195]\n",
      "[ 0.7912516]\n",
      "[ 0.78496951]\n",
      "[ 0.79307407]\n",
      "[ 0.76556534]\n",
      "[ 0.8050645]\n",
      "[ 0.76237279]\n",
      "[ 0.81066203]\n",
      "[ 0.80200815]\n",
      "[ 0.78405732]\n",
      "[ 0.76992363]\n",
      "[ 0.7575627]\n",
      "[ 0.77966106]\n",
      "[ 0.80790889]\n",
      "[ 0.82435364]\n",
      "[ 0.79049653]\n",
      "[ 0.79996634]\n",
      "[ 0.80309832]\n",
      "[ 0.77462983]\n",
      "[ 0.78958523]\n",
      "[ 0.80609471]\n",
      "[ 0.7813974]\n",
      "[ 0.77988809]\n",
      "[ 0.74845135]\n",
      "[ 0.79319352]\n",
      "[ 0.77872437]\n",
      "[ 0.79371506]\n",
      "[ 0.78470773]\n",
      "[ 0.76734883]\n",
      "[ 0.78721732]\n",
      "[ 0.79871351]\n",
      "[ 0.79671282]\n",
      "[ 0.78433734]\n",
      "[ 0.77810514]\n",
      "[ 0.76484048]\n",
      "[ 0.76590627]\n",
      "[ 0.80146199]\n",
      "[ 0.77176744]\n",
      "[ 0.77082998]\n",
      "[ 0.77868026]\n",
      "[ 0.80607229]\n",
      "[ 0.78190464]\n",
      "[ 0.77866596]\n",
      "[ 0.78103757]\n",
      "[ 0.81347638]\n",
      "[ 0.7933352]\n",
      "[ 0.78175175]\n",
      "[ 0.81059819]\n",
      "[ 0.7691974]\n",
      "[ 0.77624822]\n",
      "[ 0.78888756]\n",
      "[ 0.77494454]\n",
      "[ 0.76236308]\n",
      "[ 0.76980507]\n",
      "[ 0.81478775]\n",
      "[ 0.76673794]\n",
      "[ 0.7792632]\n",
      "[ 0.80097419]\n",
      "[ 0.79108638]\n",
      "[ 0.7728349]\n",
      "[ 0.78675628]\n",
      "[ 0.77377146]\n",
      "[ 0.78928125]\n",
      "[ 0.82015568]\n"
     ]
    }
   ],
   "source": [
    "rnn_pd.train(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2, 4, 9]), Variable containing:\n",
       "  0.0126\n",
       "  0.6001\n",
       "  0.3873\n",
       " [torch.FloatTensor of size 3])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_pd.predict([0,1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
