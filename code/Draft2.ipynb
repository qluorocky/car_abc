{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imp\n",
    "import Data\n",
    "import utils\n",
    "import Predictors, Road_Graph, Neural_Network\n",
    "imp.reload(Data)\n",
    "imp.reload(Neural_Network)\n",
    "imp.reload(utils)\n",
    "imp.reload(Predictors)\n",
    "imp.reload(Road_Graph)\n",
    "\n",
    "from Road_Graph import *\n",
    "from Predictors import *\n",
    "from Data import *\n",
    "from utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "from torch import nn, autograd\n",
    "import torch.nn.functional as F\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, we focus on a simple road map (rep as a graph below), and generate random path on it.\n",
    "<img src=\"../img/naive_road.png\" alt=\"Drawing\" style=\"width: 400px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_dict = {}\n",
    "graph_dict = graph_dict.fromkeys(range(24))\n",
    "edges = [(i, i+1) for i in range(5)] \\\n",
    "        + [(i+6, i+7) for i in range(5)]\\\n",
    "                        +[(i+12, i+13) for i in range(5)]\\\n",
    "                     + [(i+18, i+19) for i in range(5)]\\\n",
    "                     + [(0,6),(6,12), (12,18)]\\\n",
    "                     + [(pair[0]+1, pair[1]+1) for pair in [(0,6),(6,12), (12,18)]]\\\n",
    "                     + [(pair[0]+2, pair[1]+2) for pair in [(0,6),(6,12), (12,18)]]\\\n",
    "                     + [(pair[0]+3, pair[1]+3) for pair in [(0,6),(6,12), (12,18)]]\\\n",
    "                     + [(pair[0]+4, pair[1]+4) for pair in [(0,6),(6,12), (12,18)]]\\\n",
    "                     + [(pair[0]+5, pair[1]+5) for pair in [(0,6),(6,12), (12,18)]]\n",
    "for i,j in edges:\n",
    "    if not graph_dict[i]:\n",
    "        graph_dict[i] = [j]\n",
    "    else:\n",
    "        graph_dict[i].append(j)\n",
    "    if not graph_dict[j]:\n",
    "        graph_dict[j] = [i]\n",
    "    else:\n",
    "        graph_dict[j].append(i)\n",
    "\n",
    "graph = Road_Graph(graph_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markov Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_to_training_pair2(path):\n",
    "    return path[1:], path[:-1]\n",
    "\n",
    "def get_prob(x):\n",
    "    nb = graph.neighbors(x)\n",
    "    W_list = [W[j].view(-1,1) for j in nb]\n",
    "    Ws = torch.cat(W_list, dim = 1)\n",
    "    W_next = model(W[x])\n",
    "    #print('W_next:', W_next)\n",
    "    #print(W_next.size(), Ws.size())\n",
    "    W_next_rep = W_next.view(-1,1).repeat(1,Ws.size()[1])\n",
    "    #print(W_next_rep.size(), Ws.size())\n",
    "    logit = torch.sum(W_next_rep*Ws, 0)\n",
    "    prob = F.softmax(logit, dim = 0)\n",
    "    return prob\n",
    "\n",
    "def get_loss(x, y):\n",
    "    nb = graph.neighbors(x)\n",
    "    #import pdb; pdb.set_trace()\n",
    "    W_list = [W[j].view(-1,1) for j in nb]\n",
    "    Ws = torch.cat(W_list, dim = 1)\n",
    "    W_next = model(W[x])\n",
    "    #print('W_next:', W_next)\n",
    "    #print(W_next.size(), Ws.size())\n",
    "    W_next_rep = W_next.view(-1,1).repeat(1,Ws.size()[1])\n",
    "    #print(W_next_rep.size(), Ws.size())\n",
    "    logit = torch.sum(W_next_rep*Ws, 0)\n",
    "    prob = F.softmax(logit, dim = 0)\n",
    "    loss = -torch.log(prob[np.where(nb == y)])\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.FloatTensor\n",
    "\n",
    "data = random_walk_data(graph,10000)\n",
    "\n",
    "im_D = 5\n",
    "N = 24\n",
    "h_D = 100\n",
    "\n",
    "\n",
    "loss_list = []\n",
    "W = Variable(torch.randn(N,im_D).type(dtype), requires_grad=True)\n",
    "model = torch.nn.Sequential(\n",
    "        torch.nn.Linear(im_D, h_D),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(h_D, im_D),\n",
    "    )\n",
    "for k in range(len(data)):\n",
    "    path = data[k]\n",
    "    x,y = path_to_training_pair2(path)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(list(model.parameters()) + [W], lr=0.001) # remove [W] for a fixed random embeding\n",
    "    for i in range(len(x)):\n",
    "        loss = get_loss(x[i], y[i])\n",
    "        loss_list.append(loss)\n",
    "        \n",
    "    if k%50 == 0:\n",
    "        batch_loss = torch.sum(torch.cat(loss_list)) / len(loss_list)\n",
    "        optimizer.zero_grad()\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_list = []\n",
    "        print(batch_loss.data.numpy())\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = np.array([1/3,1/3,1/3])\n",
    "-np.sum(p * np.log(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opt_log_loss():\n",
    "    s = 0\n",
    "    for i in range(24):\n",
    "        p_ = get_prob(i).data.numpy()\n",
    "        n = len(get_prob(i))\n",
    "        s += -np.sum(np.ones(n) /n * np.log(np.ones(n)/n))\n",
    "    return s/24\n",
    "opt_log_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_loss():\n",
    "    s = 0\n",
    "    for i in range(24):\n",
    "        p_ = get_prob(i).data.numpy()\n",
    "        n = len(get_prob(i))\n",
    "        s += -np.sum(np.ones(n) /n * np.log(p_))\n",
    "    return s/24\n",
    "log_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_loss():\n",
    "    s = 0\n",
    "    for i in range(24):\n",
    "        p_ = get_prob(i).data.numpy()\n",
    "        n = len(get_prob(i))\n",
    "        s += -np.sum(np.ones(n) /n * np.log(p_))\n",
    "    return s/24\n",
    "log_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_prob(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hist Dependent Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, n_layers=1):\n",
    "        super(RNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.gru = nn.GRU(input_size, hidden_size, n_layers)\n",
    "        self.lin = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, inp, hidden):\n",
    "        output, hidden = self.gru(inp.view(1, 1, self.input_size), hidden)\n",
    "        output = self.lin(output) \n",
    "        return output, hidden        \n",
    "\n",
    "    def init_hidden(self):\n",
    "        return Variable(torch.zeros(self.n_layers, 1, self.hidden_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_loss(path):\n",
    "    h = model.init_hidden()\n",
    "    output_list = []\n",
    "    for i in path:\n",
    "        o, h = model(W[i], h)\n",
    "        output_list.append(o)\n",
    "    loss_list = []\n",
    "    for i in range(len(path) - 1):\n",
    "        x = path[i]\n",
    "        y = path[i+1]\n",
    "        nb = graph.neighbors(x)\n",
    "        W_list = [W[j].view(-1,1) for j in nb]\n",
    "        Ws = torch.cat(W_list, dim = 1)\n",
    "        W_next = output_list[i]\n",
    "        W_next_rep = W_next.view(-1,1).repeat(1,Ws.size()[1])\n",
    "        logit = torch.sum(W_next_rep*Ws, 0)\n",
    "        prob = F.softmax(logit, dim = 0)\n",
    "        loss_list.append(-torch.log(prob[np.where(nb == y)]))\n",
    "    return torch.sum(torch.cat(loss_list))\n",
    "\n",
    "def get_prob(path):\n",
    "    h = model.init_hidden()\n",
    "    for i in path:\n",
    "        o, h = model(W[i], h)\n",
    "    x = path[-1]\n",
    "    nb = graph.neighbors(x)\n",
    "    W_list = [W[j].view(-1,1) for j in nb]\n",
    "    Ws = torch.cat(W_list, dim = 1)\n",
    "    W_next = o\n",
    "    W_next_rep = W_next.view(-1,1).repeat(1,Ws.size()[1])\n",
    "    logit = torch.sum(W_next_rep*Ws, 0)\n",
    "    prob = F.softmax(logit, dim = 0)\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = random_walk_data(graph, 10000, go_back=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_D = 50\n",
    "N = 24\n",
    "h_D = 100\n",
    "dtype = torch.FloatTensor\n",
    "\n",
    "\n",
    "W = Variable(torch.randn(N,im_D).type(dtype), requires_grad=True)\n",
    "model = RNN(im_D, h_D, im_D)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) # remove [W] for a fixed random embeding\n",
    "\n",
    "loss_list = []\n",
    "s = 0\n",
    "for k in range(len(data)):\n",
    "    path = data[k]\n",
    "    loss = path_loss(path)\n",
    "    loss_list.append(loss)    \n",
    "    s += len(path)\n",
    "    if k%50 == 0:\n",
    "        batch_loss = torch.sum(torch.cat(loss_list)) / s\n",
    "        s = 0\n",
    "        optimizer.zero_grad()\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_list = []\n",
    "        print(batch_loss.data.numpy())\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_prob([1,2,3,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modulized Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = random_walk_data(graph, 10000, go_back=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_pd = RNN_Predictor(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.43386555]\n",
      "[ 1.28774869]\n",
      "[ 1.34153068]\n",
      "[ 1.27314484]\n",
      "[ 1.23466599]\n",
      "[ 1.19762063]\n",
      "[ 1.17873383]\n",
      "[ 1.15821397]\n",
      "[ 1.16038024]\n",
      "[ 1.04382944]\n",
      "[ 1.09409392]\n",
      "[ 1.04834044]\n",
      "[ 1.07298815]\n",
      "[ 1.04028487]\n",
      "[ 0.95232373]\n",
      "[ 0.98204458]\n",
      "[ 0.97956848]\n",
      "[ 0.95116878]\n",
      "[ 0.94344908]\n",
      "[ 0.87796742]\n",
      "[ 0.95411146]\n",
      "[ 0.85435915]\n",
      "[ 0.89130545]\n",
      "[ 0.87831348]\n",
      "[ 0.89541167]\n",
      "[ 0.89544797]\n",
      "[ 0.89993894]\n",
      "[ 0.88904434]\n",
      "[ 0.86201966]\n",
      "[ 0.85485506]\n",
      "[ 0.89148772]\n",
      "[ 0.87167549]\n",
      "[ 0.86684632]\n",
      "[ 0.8418957]\n",
      "[ 0.86877811]\n",
      "[ 0.84373087]\n",
      "[ 0.817586]\n",
      "[ 0.83476841]\n",
      "[ 0.88498414]\n",
      "[ 0.82680124]\n",
      "[ 0.89422202]\n",
      "[ 0.82049465]\n",
      "[ 0.82078958]\n",
      "[ 0.83400857]\n",
      "[ 0.87270308]\n",
      "[ 0.83814883]\n",
      "[ 0.82032931]\n",
      "[ 0.84316963]\n",
      "[ 0.79578835]\n",
      "[ 0.83615142]\n",
      "[ 0.87918681]\n",
      "[ 0.79129088]\n",
      "[ 0.82373762]\n",
      "[ 0.84966844]\n",
      "[ 0.8332417]\n",
      "[ 0.8528778]\n",
      "[ 0.83399636]\n",
      "[ 0.8213982]\n",
      "[ 0.86966777]\n",
      "[ 0.81227708]\n",
      "[ 0.83005953]\n",
      "[ 0.83015913]\n",
      "[ 0.80657768]\n",
      "[ 0.8018437]\n",
      "[ 0.79199207]\n",
      "[ 0.77938694]\n",
      "[ 0.81173289]\n",
      "[ 0.81711346]\n",
      "[ 0.81508952]\n",
      "[ 0.81835002]\n",
      "[ 0.77864885]\n",
      "[ 0.83912337]\n",
      "[ 0.81126881]\n",
      "[ 0.84596819]\n",
      "[ 0.81292021]\n",
      "[ 0.83073699]\n",
      "[ 0.85489976]\n",
      "[ 0.81517464]\n",
      "[ 0.84653962]\n",
      "[ 0.81031126]\n",
      "[ 0.78606546]\n",
      "[ 0.8259542]\n",
      "[ 0.79050821]\n",
      "[ 0.81934255]\n",
      "[ 0.84134179]\n",
      "[ 0.80994523]\n",
      "[ 0.85646826]\n",
      "[ 0.79950339]\n",
      "[ 0.80843443]\n",
      "[ 0.80816859]\n",
      "[ 0.81420273]\n",
      "[ 0.81510693]\n",
      "[ 0.85496563]\n",
      "[ 0.79120326]\n",
      "[ 0.81694728]\n",
      "[ 0.80311334]\n",
      "[ 0.77723932]\n",
      "[ 0.80933768]\n",
      "[ 0.81932151]\n",
      "[ 0.82242072]\n",
      "[ 0.81480384]\n",
      "[ 0.76068383]\n",
      "[ 0.79097515]\n",
      "[ 0.81003535]\n",
      "[ 0.82126492]\n",
      "[ 0.7978999]\n",
      "[ 0.8009789]\n",
      "[ 0.82042605]\n",
      "[ 0.82654959]\n",
      "[ 0.82351732]\n",
      "[ 0.78946978]\n",
      "[ 0.80632019]\n",
      "[ 0.81999665]\n",
      "[ 0.80429316]\n",
      "[ 0.77461332]\n",
      "[ 0.78469241]\n",
      "[ 0.78209662]\n",
      "[ 0.81044006]\n",
      "[ 0.78624815]\n",
      "[ 0.81143963]\n",
      "[ 0.79405004]\n",
      "[ 0.79160118]\n",
      "[ 0.77124453]\n",
      "[ 0.81500149]\n",
      "[ 0.80784029]\n",
      "[ 0.83646131]\n",
      "[ 0.81930494]\n"
     ]
    }
   ],
   "source": [
    "rnn_pd.train(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.graph.number_of_nodes()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
