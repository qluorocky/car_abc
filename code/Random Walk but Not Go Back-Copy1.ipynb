{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import torch\n",
    "import time\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from torch.autograd import Variable\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, we focus on a simple road map (rep as a graph below), and generate random path on it.\n",
    "<img src=\"img/naive_road.png\" alt=\"Drawing\" style=\"width: 400px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(x, N = 24):\n",
    "    l = np.zeros(24)\n",
    "    l[x] = 1\n",
    "    return l\n",
    "def inv_one_hot(l, N = 24):\n",
    "    return np.argmax(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_graph():\n",
    "    G=nx.Graph()\n",
    "    G.add_nodes_from(range(24))\n",
    "    G.add_edges_from([(i, i+1) for i in range(5)] \n",
    "                     + [(i+6, i+7) for i in range(5)] \n",
    "                     +[(i+12, i+13) for i in range(5)]\n",
    "                     + [(i+18, i+19) for i in range(5)]\n",
    "                     + [(0,6),(6,12), (12,18)]\n",
    "                     + [(pair[0]+1, pair[1]+1) for pair in [(0,6),(6,12), (12,18)]]\n",
    "                     + [(pair[0]+2, pair[1]+2) for pair in [(0,6),(6,12), (12,18)]]\n",
    "                     + [(pair[0]+3, pair[1]+3) for pair in [(0,6),(6,12), (12,18)]]\n",
    "                     + [(pair[0]+4, pair[1]+4) for pair in [(0,6),(6,12), (12,18)]]\n",
    "                     + [(pair[0]+5, pair[1]+5) for pair in [(0,6),(6,12), (12,18)]]\n",
    "                     )\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gloable env\n",
    "G = build_graph() \n",
    "N = len(G.node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_path(start = None, stop_prob = 0.1):\n",
    "    \"\"\"\n",
    "    Generate (hist dependent) random path on graph G with lenght at least 2, encode each road in one-hot fashion\n",
    "    \"\"\"\n",
    "    if not start:\n",
    "        start = np.random.choice(24)\n",
    "    path = [start]\n",
    "    prev = None\n",
    "    while True:\n",
    "        neighbors = list(G.neighbors(start))\n",
    "        if prev:\n",
    "            neighbors.remove(prev)\n",
    "        nxt = np.random.choice(neighbors)\n",
    "        path.append(nxt)\n",
    "        prev = start\n",
    "        start = nxt\n",
    "        if np.random.rand() < stop_prob:\n",
    "            break\n",
    "    return np.array(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_training_set():\n",
    "    def f(x):\n",
    "        if x == -1:\n",
    "            return 0\n",
    "        if x == -6:\n",
    "            return 1\n",
    "        if x == 1:\n",
    "            return 2\n",
    "        if x == 6:\n",
    "            return 3\n",
    "    path = random_path()\n",
    "    inp = torch.from_numpy(np.float32(np.array([one_hot(p) for p in path[:-1]])))\n",
    "    #import pdb; pdb.set_trace()\n",
    "    tar = [f(x) for x in path[1:] - path[:-1]]\n",
    "    tar = torch.from_numpy(np.array(tar))\n",
    "    return Variable(inp).contiguous(), Variable(tar).contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [6, 0, 1, 0, 6, 0, 1, 0, 6, 12, 13, 19, 20, 21, 15, 14] is the sequence of road\n",
      "y: [1 2 0 3 1 2 0 3 3 2 3 2 2 1 0 0] denotes the turning decistion at each road\n"
     ]
    }
   ],
   "source": [
    "x,y = random_training_set()\n",
    "print('x: {} is the sequence of road'.format([inv_one_hot(r) for r in x.data.numpy()]))\n",
    "print('y: {} denotes the turning decistion at each road'.format(y.data.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 24])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we know the road transition are markov (turing decision only depends on current road), let start with *none-recurrent nn* to fit our transition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.38878762722\n",
      "1000 1.34971378732\n",
      "2000 1.3314701997\n",
      "3000 1.32855399197\n",
      "4000 1.32867008865\n",
      "5000 1.32643869925\n",
      "6000 1.32714650661\n",
      "7000 1.32548642629\n",
      "8000 1.32881623989\n",
      "9000 1.32696944189\n",
      "10000 1.32220522338\n",
      "11000 1.3258631013\n",
      "12000 1.32731270623\n",
      "13000 1.32596182746\n",
      "14000 1.32388681716\n",
      "15000 1.32109983599\n",
      "16000 1.32240766013\n",
      "17000 1.32555015326\n",
      "18000 1.32163364619\n",
      "19000 1.32320301169\n",
      "20000 1.32298102039\n",
      "21000 1.32587729132\n",
      "22000 1.32072102463\n",
      "23000 1.32467345208\n",
      "24000 1.32116918778\n",
      "25000 1.32340651631\n",
      "26000 1.32216803819\n",
      "27000 1.31961091661\n",
      "28000 1.32020789051\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-79fbc658234c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/TF/lib/python3.6/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     76\u001b[0m                 \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "N_batch, D_in, D_hidden, D_out = 50, 24, 100, 4\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(D_in, D_hidden),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(D_hidden, D_out),\n",
    "    torch.nn.Softmax(dim = 1),\n",
    ")\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "learning_rate = 0.002\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "L = 0\n",
    "n = 0\n",
    "pts = {'x':[], 'y':[]}\n",
    "for t in range(40000):\n",
    "    x,y = random_training_set()\n",
    "    y_pred = model(x)\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    L += sum(loss.data.numpy())\n",
    "    n += len(loss.data.numpy())\n",
    "    if t%1000 == 0:\n",
    "        pts['x'].append(t)\n",
    "        pts['y'].append(L/n)\n",
    "        print(t, L/n)\n",
    "        L = 0\n",
    "        n = 0\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(pts['x'],pts['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = random_training_set()\n",
    "print([inv_one_hot(r) for r in x.data.numpy()])\n",
    "model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, the naive nn is not enough.\n",
    "# RNN for Tracking the History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_prob' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-66a93a58365a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m24\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mopt_log_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-66a93a58365a>\u001b[0m in \u001b[0;36mopt_log_loss\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m24\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mp_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_prob' is not defined"
     ]
    }
   ],
   "source": [
    "def opt_log_loss():\n",
    "    s = 0\n",
    "    for i in range(24):\n",
    "        p_ = get_prob(i).data.numpy()\n",
    "        n = len(get_prob(i)) - 1\n",
    "        s += -np.sum(np.ones(n) /n * np.log(np.ones(n)/n))\n",
    "    return s/24\n",
    "opt_log_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, n_layers=1):\n",
    "        super(RNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.gru = nn.GRU(input_size, hidden_size, n_layers)\n",
    "        self.lin = nn.Linear(hidden_size, output_size)\n",
    "        self.sm = nn.Softmax(dim = 2)\n",
    "        \n",
    "        hidden0 = torch.zeros(n_layers, 1, hidden_size)\n",
    "        self.hidden0 = nn.Parameter(hidden0, requires_grad=True)\n",
    "    \n",
    "    def forward(self, inp, hidden):\n",
    "        output, hidden = self.gru(inp.view(1, 1, self.input_size), hidden)\n",
    "        output = self.lin(output) \n",
    "        output = self.sm(output)\n",
    "        return output, hidden\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        return self.hidden0\n",
    "    #def init_hidden(self):\n",
    "    #    return Variable(torch.zeros(self.n_layers, 1, self.hidden_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(inp, target):\n",
    "    hidden = rnn.init_hidden() \n",
    "    rnn.zero_grad()\n",
    "    hat = []\n",
    "    for i in range(len(inp)):\n",
    "        output, hidden = rnn(inp[i,:], hidden)\n",
    "        hat.append(output.view(-1,4))\n",
    "    pred = torch.cat(hat)\n",
    "    loss = loss_fn(pred, target)\n",
    "    rnn_optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    rnn_optimizer.step()\n",
    "    return pred, loss.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 1.286091720533371\n",
      "20000 1.2516227767646313\n",
      "30000 1.2476900822401047\n",
      "40000 1.2422941454291343\n",
      "50000 1.2401497869372369\n",
      "60000 1.2390156372785568\n",
      "70000 1.2365963279604912\n",
      "80000 1.2335477594792843\n",
      "90000 1.2303391821324825\n",
      "100000 1.230012923693657\n",
      "110000 1.2306775426208973\n",
      "120000 1.2277813690721988\n",
      "130000 1.2270576486170293\n",
      "140000 1.2276011325895786\n",
      "150000 1.2275342661499977\n",
      "160000 1.228600606149435\n",
      "170000 1.2282477041065694\n",
      "180000 1.228779377555847\n",
      "190000 1.2264574523568152\n",
      "200000 1.226555451208353\n",
      "210000 1.2266811502873898\n",
      "220000 1.2266467179477214\n",
      "230000 1.2258391895890235\n",
      "240000 1.227276900303364\n",
      "250000 1.2261577071368694\n",
      "260000 1.226163866341114\n",
      "270000 1.2274386729240419\n",
      "280000 1.2247353821992875\n",
      "290000 1.2273381299853325\n",
      "300000 1.225574891871214\n",
      "310000 1.2249735207259655\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-3dde353c29c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m400001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_training_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mL\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-32-61429cd69030>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(inp, target)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mrnn_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mrnn_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/TF/lib/python3.6/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     70\u001b[0m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m                 \u001b[0mbias_correction1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'step'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "N_batch, D_in, D_hidden, D_out = 50, 24, 200, 4\n",
    "rnn = RNN(D_in, D_hidden, D_out, n_layers = 1)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "learning_rate = 0.0002\n",
    "rnn_optimizer = torch.optim.Adam(rnn.parameters(), lr=learning_rate)\n",
    "L = 0\n",
    "pts = {'x':[], 'y':[]}\n",
    "for t in range(1,400001):\n",
    "    x,y = random_training_set()\n",
    "    _, loss = train(x,y)\n",
    "    \n",
    "    L += loss\n",
    "    if t%10000 == 0:\n",
    "        pts['x'].append(t)\n",
    "        pts['y'].append(L/10000)\n",
    "        print(t, L/10000)\n",
    "        L = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1134ee668>]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1121acdd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(pts['x'],pts['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13, 7, 8, 2, 3, 4]\n",
      "Variable containing:\n",
      " 3.3245e-01  1.9453e-01  2.1593e-01  2.5709e-01\n",
      " 2.6542e-01  4.3333e-01  2.8481e-01  1.6435e-02\n",
      " 9.0449e-03  5.1083e-01  3.2381e-01  1.5632e-01\n",
      " 3.9767e-01  1.9064e-05  5.9889e-01  3.4207e-03\n",
      " 4.9464e-03  8.7184e-06  6.1532e-01  3.7973e-01\n",
      " 5.5006e-03  4.6562e-06  6.3331e-01  3.6119e-01\n",
      "[torch.FloatTensor of size 6x4]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x,y = random_training_set()\n",
    "pred,_ = train(x,y)\n",
    "print([inv_one_hot(r) for r in x.data.numpy()])\n",
    "print(pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
