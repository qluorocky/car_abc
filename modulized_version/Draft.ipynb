{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'Data' from '/Users/haoyuan/Desktop/codes/didi/under_version_control/Hao/Didi_project/Data.py'>"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import imp\n",
    "import Data\n",
    "imp.reload(Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Road_Graph import *\n",
    "from Predictors import *\n",
    "from Data import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, we focus on a simple road map (rep as a graph below), and generate random path on it.\n",
    "<img src=\"../img/naive_road.png\" alt=\"Drawing\" style=\"width: 400px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build the road graph as above\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_dict = {}\n",
    "graph_dict = graph_dict.fromkeys(range(24))\n",
    "edges = [(i, i+1) for i in range(5)] \\\n",
    "        + [(i+6, i+7) for i in range(5)]\\\n",
    "                        +[(i+12, i+13) for i in range(5)]\\\n",
    "                     + [(i+18, i+19) for i in range(5)]\\\n",
    "                     + [(0,6),(6,12), (12,18)]\\\n",
    "                     + [(pair[0]+1, pair[1]+1) for pair in [(0,6),(6,12), (12,18)]]\\\n",
    "                     + [(pair[0]+2, pair[1]+2) for pair in [(0,6),(6,12), (12,18)]]\\\n",
    "                     + [(pair[0]+3, pair[1]+3) for pair in [(0,6),(6,12), (12,18)]]\\\n",
    "                     + [(pair[0]+4, pair[1]+4) for pair in [(0,6),(6,12), (12,18)]]\\\n",
    "                     + [(pair[0]+5, pair[1]+5) for pair in [(0,6),(6,12), (12,18)]]\n",
    "for i,j in edges:\n",
    "    if not graph_dict[i]:\n",
    "        graph_dict[i] = [j]\n",
    "    else:\n",
    "        graph_dict[i].append(j)\n",
    "    if not graph_dict[j]:\n",
    "        graph_dict[j] = [i]\n",
    "    else:\n",
    "        graph_dict[j].append(i)\n",
    "\n",
    "#display(graph_dict)\n",
    "graph = Road_Graph(graph_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14, 20, 19, 13, 14, 15,  9,  3,  4])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_path_not_back(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 2, 1, 3]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = [1,2,3,4]\n",
    "np.random.shuffle(s)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = random_walk_data(graph, 30,go_back = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_training_set(graph, data, batch_size):\n",
    "    def f(x):\n",
    "        if x == -1:\n",
    "            return 0\n",
    "        if x == -6:\n",
    "            return 1\n",
    "        if x == 1:\n",
    "            return 2\n",
    "        if x == 6:\n",
    "            return 3\n",
    "    path = random_path()\n",
    "    inp = torch.from_numpy(np.float32(np.array([one_hot(p) for p in path[:-1]])))\n",
    "    #import pdb; pdb.set_trace()\n",
    "    tar = [f(x) for x in path[1:] - path[:-1]]\n",
    "    tar = torch.from_numpy(np.array(tar))\n",
    "    return Variable(inp).contiguous(), Variable(tar).contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_training_set():\n",
    "    def f(x):\n",
    "        if x == -1:\n",
    "            return 0\n",
    "        if x == -6:\n",
    "            return 1\n",
    "        if x == 1:\n",
    "            return 2\n",
    "        if x == 6:\n",
    "            return 3\n",
    "    path = random_path()\n",
    "    inp = torch.from_numpy(np.float32(np.array([one_hot(p) for p in path[:-1]])))\n",
    "    #import pdb; pdb.set_trace()\n",
    "    tar = [f(x) for x in path[1:] - path[:-1]]\n",
    "    tar = torch.from_numpy(np.array(tar))\n",
    "    return Variable(inp).contiguous(), Variable(tar).contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_training_set_with_road_tar():\n",
    "    path = random_path()\n",
    "    inp = torch.from_numpy(np.float32(np.array([one_hot(p) for p in path[:-1]])))\n",
    "    tar = torch.from_numpy(np.array(path[1:]))\n",
    "    return Variable(inp).contiguous(), Variable(tar).contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = random_training_set()\n",
    "print('x: {} is the sequence of road'.format([inv_one_hot(r) for r in x.data.numpy()]))\n",
    "print('y: {} denotes the turning decistion at each road'.format(y.data.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = random_training_set_with_road_tar()\n",
    "print('x: {} is the sequence of road'.format([inv_one_hot(r) for r in x.data.numpy()]))\n",
    "print('y: {} is the sequence of road'.format(y.data.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {'batch_zie' : 30, 'learning_rate': 0.01, 'steps:': 1000}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(config = {'batch_size' : 30, 'learning_rate': 0.01, 'steps:': 1000}):\n",
    "    pass "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we know the road transition are markov (turing decision only depends on current road), let start with *none-recurrent nn* to fit our transition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_batch, D_in, D_hidden, D_out = 50, 24, 100, 4\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(D_in, D_hidden),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(D_hidden, D_out),\n",
    "    torch.nn.Softmax(dim = 1),\n",
    ")\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "learning_rate = 0.002\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "L = 0\n",
    "n = 0\n",
    "pts = {'x':[], 'y':[]}\n",
    "for t in range(1,40001):\n",
    "    x,y = random_training_set()\n",
    "    y_pred = model(x)\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    L += sum(loss.data.numpy())\n",
    "    n += len(loss.data.numpy())\n",
    "    if t%1000 == 0:\n",
    "        pts['x'].append(t)\n",
    "        pts['y'].append(L/n)\n",
    "        print(t, L/n)\n",
    "        L = 0\n",
    "        n = 0\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(pts['x'],pts['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = random_training_set()\n",
    "print([inv_one_hot(r) for r in x.data.numpy()])\n",
    "model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_batch, D_in, D_hidden, D_out = 50, 24, 100, 24\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(D_in, D_hidden),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(D_hidden, D_out),\n",
    "    torch.nn.Softmax(dim = 1),\n",
    ")\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "learning_rate = 0.002\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "L = 0\n",
    "n = 0\n",
    "pts = {'x':[], 'y':[]}\n",
    "for t in range(1,40001):\n",
    "    x,y = random_training_set_with_road_tar()\n",
    "    y_pred = model(x)\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    L += sum(loss.data.numpy())\n",
    "    n += len(loss.data.numpy())\n",
    "    if t%1000 == 0:\n",
    "        pts['x'].append(t)\n",
    "        pts['y'].append(L/n)\n",
    "        print(t, L/n)\n",
    "        L = 0\n",
    "        n = 0\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = random_training_set_with_road_tar()\n",
    "print([inv_one_hot(r) for r in x.data.numpy()])\n",
    "np.concatenate([model(x)[0,:].data.numpy().reshape(24,1), \n",
    "                np.array(range(0,24)).reshape(24,1)],\n",
    "               axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input\n",
    "output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
