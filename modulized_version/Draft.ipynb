{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imp\n",
    "import Data\n",
    "import utils\n",
    "import Predictors\n",
    "imp.reload(Data)\n",
    "imp.reload(utils)\n",
    "imp.reload(Predictors)\n",
    "\n",
    "from Road_Graph import *\n",
    "from Predictors import *\n",
    "from Data import *\n",
    "from utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "from torch import nn, autograd\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, we focus on a simple road map (rep as a graph below), and generate random path on it.\n",
    "<img src=\"../img/naive_road.png\" alt=\"Drawing\" style=\"width: 400px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build the road graph as above\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_dict = {}\n",
    "graph_dict = graph_dict.fromkeys(range(24))\n",
    "edges = [(i, i+1) for i in range(5)] \\\n",
    "        + [(i+6, i+7) for i in range(5)]\\\n",
    "                        +[(i+12, i+13) for i in range(5)]\\\n",
    "                     + [(i+18, i+19) for i in range(5)]\\\n",
    "                     + [(0,6),(6,12), (12,18)]\\\n",
    "                     + [(pair[0]+1, pair[1]+1) for pair in [(0,6),(6,12), (12,18)]]\\\n",
    "                     + [(pair[0]+2, pair[1]+2) for pair in [(0,6),(6,12), (12,18)]]\\\n",
    "                     + [(pair[0]+3, pair[1]+3) for pair in [(0,6),(6,12), (12,18)]]\\\n",
    "                     + [(pair[0]+4, pair[1]+4) for pair in [(0,6),(6,12), (12,18)]]\\\n",
    "                     + [(pair[0]+5, pair[1]+5) for pair in [(0,6),(6,12), (12,18)]]\n",
    "for i,j in edges:\n",
    "    if not graph_dict[i]:\n",
    "        graph_dict[i] = [j]\n",
    "    else:\n",
    "        graph_dict[i].append(j)\n",
    "    if not graph_dict[j]:\n",
    "        graph_dict[j] = [i]\n",
    "    else:\n",
    "        graph_dict[j].append(i)\n",
    "\n",
    "#display(graph_dict)\n",
    "graph = Road_Graph(graph_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = random_walk_data(graph, 10000,go_back = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mk_pd = Markov_Predictor(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 3 8] [ 0.33386924  0.33386924  0.33226152]\n"
     ]
    }
   ],
   "source": [
    "mk_pd.train(data)\n",
    "nxt,prob = mk_pd.predict([0,1,2])\n",
    "print(nxt, prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.61312825514869762"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mk_pd.eval(random_walk_data(graph, 1000,go_back = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm_pd = Random_Predictor(graph)\n",
    "rm_pd.eval(random_walk_data(graph, 1000,go_back = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F.cross_entropy\n",
    "log_loss(nxt == 3, prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_set(path, graph):\n",
    "    N = len(graph.nodes)\n",
    "    n = len(path)\n",
    "    inp = torch.from_numpy(np.float32(np.array([one_hot(p, N) for p in path[:-1]])))\n",
    "    tar = [int(np.where(graph.neighbors(path[i]) == path[i+1])[0]) for i in range(n - 1)]\n",
    "    tar = torch.from_numpy(np.array(tar))\n",
    "    return Variable(inp).contiguous(), Variable(tar).contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def train(self, data, batch_size = 50, learning_rate = 0.001, steps = 10000):                                                                                                  \n",
    "data = random_walk_data(graph, 10000,go_back = True)\n",
    "\n",
    "batch_size = 50\n",
    "learning_rate = 0.001 \n",
    "steps = 1000\n",
    "D_in, D_hidden, D_out = len(graph.nodes), 100, 4                                                                                                                      \n",
    "\n",
    "model = torch.nn.Sequential(                                                                                                                                               \n",
    "    torch.nn.Linear(D_in, D_hidden),                                                                                                                                       \n",
    "    torch.nn.ReLU(),                                                                                                                                                       \n",
    "    torch.nn.Linear(D_hidden, D_out),\n",
    "    torch.nn.Softmax(dim = 1)\n",
    ")                                                                                                                                             \n",
    "loss_fn = torch.nn.CrossEntropyLoss()                                                                                                                                      \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)                                                                                                         \n",
    "num_batch = len(data) // batch_size\n",
    "\n",
    "losses = []\n",
    "for t in range(1,steps+1):\n",
    "    if t%100 == 0:\n",
    "        print(t)\n",
    "    i = t % num_batch\n",
    "    data_i = data[i*batch_size:(i+1)*batch_size]\n",
    "    batch_loss = Variable(torch.zeros(1), requires_grad=True)\n",
    "    num_road = 0\n",
    "    y_pred_list = []\n",
    "    y_list = []\n",
    "    for path in data_i:\n",
    "        x,y = training_set(path, graph)                                                                                                                                          \n",
    "        y_pred = model(x)                                                                                                                                                      \n",
    "        loss = loss_fn(y_pred, y) * len(y) # TODO: truancate y_pred, Contatinate\n",
    "        batch_loss = batch_loss + loss\n",
    "        num_road = num_road + len(y)\n",
    "    batch_loss /= num_road\n",
    "    #print(batch_loss.data[0])\n",
    "    losses.append(batch_loss.data[0])\n",
    "    if i == 0:\n",
    "        np.random.shuffle(data)\n",
    "    optimizer.zero_grad()                                                                                                                                                  \n",
    "    batch_loss.backward()                                                                                                                                                        \n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.sum(prob,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reweight(prob, cut):\n",
    "    a,b = prob.size()\n",
    "    for i in range(len(cut)):\n",
    "        n = cut[i]\n",
    "        if n < b:\n",
    "            prob[i,n:] = 0\n",
    "            prob[i, :n] = prob[i, :n] / torch.sum(prob[i, :n])\n",
    "    return prob\n",
    "\n",
    "def count_exit(path):\n",
    "    return [len(graph.neighbors(i)) for i in path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = F.softmax(autograd.Variable(torch.randn(2, 3)), dim = 1)\n",
    "cut = [1,2]\n",
    "reweight(prob,cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = {0:{1:1, 2:4}, 1:{0:1,2:1}}\n",
    "np.array(list(table[0])) / sum(list(table[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def train(self, data, batch_size = 50, learning_rate = 0.001, steps = 10000):                                                                                                  \n",
    "data = random_walk_data(graph, 10000,go_back = True)\n",
    "\n",
    "batch_size = 50\n",
    "learning_rate = 0.001 \n",
    "steps = 1000\n",
    "D_in, D_hidden, D_out = len(graph.nodes), 100, 4                                                                                                                      \n",
    "\n",
    "model = torch.nn.Sequential(                                                                                                                                               \n",
    "    torch.nn.Linear(D_in, D_hidden),                                                                                                                                       \n",
    "    torch.nn.ReLU(),                                                                                                                                                       \n",
    "    torch.nn.Linear(D_hidden, D_out),\n",
    "    torch.nn.Softmax(dim = 1)\n",
    ")\n",
    "\n",
    "    \n",
    "loss_fn = torch.nn.CrossEntropyLoss()                                                                                                                                      \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)                                                                                                         \n",
    "num_batch = len(data) // batch_size\n",
    "\n",
    "losses = []\n",
    "for t in range(1,steps+1):\n",
    "    if t%100 == 0:\n",
    "        print(t)\n",
    "    i = t % num_batch\n",
    "    data_i = data[i*batch_size:(i+1)*batch_size]\n",
    "    batch_loss = Variable(torch.zeros(1), requires_grad=True)\n",
    "    num_road = 0\n",
    "    y_pred_list = []\n",
    "    y_list = []\n",
    "    for path in data_i:\n",
    "        num_exit = count_exit(path)[:-1]\n",
    "        x,y = training_set(path, graph)                                                                                                                                          \n",
    "        y_pred = reweight(model(x),num_exit)\n",
    "        y_list.append(y)\n",
    "        y_pred_list.append(y_pred)\n",
    "        \n",
    "    batch_loss = loss_fn(torch.cat(y_pred_list), torch.cat(y_list))\n",
    "        #num_road = num_road + len(y)\n",
    "    #batch_loss /= num_road\n",
    "    losses.append(batch_loss.data[0])\n",
    "    if i == 0:\n",
    "        print(batch_loss.data[0])\n",
    "        np.random.shuffle(data)\n",
    "    optimizer.zero_grad()                                                                                                                                                  \n",
    "    batch_loss.backward()                                                                                                                                                        \n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = training_set(path, graph)\n",
    "path = [len(graph.neighbors(inv_one_hot(r)))  for r in x.data.numpy()]\n",
    "print(path)\n",
    "l = [len(graph.neighbors(r))  for r in path]\n",
    "y_  = model(x)\n",
    "#print(y_)\n",
    "\n",
    "def f(y_, l):\n",
    "    for i in range(len(l)):\n",
    "        print(y_[i,:l[i]]) #=  y_[i,:[i]] / torch.sum(y_[i,:[i]])\n",
    "        print(y_[i,l[i]:]) #= 0\n",
    "f(y_,l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_batch, D_in, D_hidden, D_out = 50, 24, 100, 4\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(D_in, D_hidden),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(D_hidden, D_out),\n",
    "    torch.nn.Softmax(dim = 1),\n",
    ")\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "learning_rate = 0.002\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "L = 0\n",
    "n = 0\n",
    "pts = {'x':[], 'y':[]}\n",
    "for t in range(1,40001):\n",
    "    x,y = random_training_set()\n",
    "    y_pred = model(x)\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    L += sum(loss.data.numpy())\n",
    "    n += len(loss.data.numpy())\n",
    "    if t%1000 == 0:\n",
    "        pts['x'].append(t)\n",
    "        pts['y'].append(L/n)\n",
    "        print(t, L/n)\n",
    "        L = 0\n",
    "        n = 0\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(pts['x'],pts['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_batch, D_in, D_hidden, D_out = 50, 24, 100, 24\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(D_in, D_hidden),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(D_hidden, D_out),\n",
    "    torch.nn.Softmax(dim = 1),\n",
    ")\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "learning_rate = 0.002\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "L = 0\n",
    "n = 0\n",
    "pts = {'x':[], 'y':[]}\n",
    "for t in range(1,40001):\n",
    "    x,y = random_training_set_with_road_tar()\n",
    "    y_pred = model(x)\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    L += sum(loss.data.numpy())\n",
    "    n += len(loss.data.numpy())\n",
    "    if t%1000 == 0:\n",
    "        pts['x'].append(t)\n",
    "        pts['y'].append(L/n)\n",
    "        print(t, L/n)\n",
    "        L = 0\n",
    "        n = 0\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = random_training_set_with_road_tar()\n",
    "print([inv_one_hot(r) for r in x.data.numpy()])\n",
    "np.concatenate([model(x)[0,:].data.numpy().reshape(24,1), \n",
    "                np.array(range(0,24)).reshape(24,1)],\n",
    "               axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input\n",
    "output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
